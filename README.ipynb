{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "\n",
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Fashin Image Recommender Bot. Deep Learning Image Recommender System with ResNet50**\n",
        "</div>\n",
        "\n",
        "The goal of this project is to create a sophisticated image recommender system that leverages the power of deep learning. The system utilizes the ResNet50 architecture, a deep convolutional neural network, to extract meaningful features from images and provide accurate recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Install Dependencies**\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "OrN9jexXL_OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Download Dataset**\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "2fGIT0HrMIRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "git clone https://github.com/alexeygrigorev/clothing-dataset.git"
      ],
      "metadata": {
        "id": "zFx-GpqlTMfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "or"
      ],
      "metadata": {
        "id": "BMCGxhcbTP8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " wget https://github.com/alexeygrigorev/clothing-dataset/archive/refs/heads/master.zip\n",
        " unzip master.zip"
      ],
      "metadata": {
        "id": "U2ezZ08tTvaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "move this images folder into current project directory"
      ],
      "metadata": {
        "id": "xhRfX3X9Txgw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Training the Model**\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "1.  **Importing Libraries:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ],
      "metadata": {
        "id": "jYZ4JW_AMP7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **TensorFlow** is imported as tensorflow.\n",
        "*   Specific modules from TensorFlow and Keras are imported for image preprocessing and ResNet50 model.\n",
        "*   **numpy** is imported as np for numerical operations.\n",
        "*   **os** is imported for operating system-related functions.\n",
        "*   **tqdm** is used to show progress bars during iterations.\n",
        "*   **pickle** is used for serializing and deserializing Python objects.\n"
      ],
      "metadata": {
        "id": "vgTXLOzHMcBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2.   **Loading Pre-trained ResNet50 Model:**"
      ],
      "metadata": {
        "id": "i4mtD8-TVZbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model.trainable = False"
      ],
      "metadata": {
        "id": "ifJHb_XNVeiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The ResNet50 model is loaded with pre-trained ImageNet weights.\n",
        "*   The `include_top=False` parameter excludes the fully connected layers at the top of the network.\n",
        "\n",
        "*   The input shape is set to (224, 224, 3).\n",
        "*   The model is set to be non-trainable (trainable=False) to use it as a fixed feature extractor.\n",
        "\n",
        "\n",
        "\n",
        "3. **Creating a Sequential Model:**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0y8Ai1T3VhvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tensorflow.keras.Sequential([\n",
        "    model,\n",
        "    GlobalMaxPooling2D()\n",
        "])"
      ],
      "metadata": {
        "id": "Rlu2l9T5VUWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The ResNet50 model is wrapped in a new sequential model, followed by a GlobalMaxPooling2D layer.\n",
        "*   Global max pooling reduces the spatial dimensions of the input tensor while retaining important information.\n",
        "\n",
        "\n",
        "\n",
        "4.  **Function to Extract Features from an Image:**\n"
      ],
      "metadata": {
        "id": "Ds_s3f0CWHIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img_path,model):\n",
        "    img = image.load_img(img_path,target_size=(224,224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "    preprocessed_img = preprocess_input(expanded_img_array)\n",
        "    result = model.predict(preprocessed_img).flatten()\n",
        "    normalized_result = result / norm(result)\n",
        "\n",
        "    return normalized_result"
      ],
      "metadata": {
        "id": "yYdBwrJxWk1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   This function takes an image path and the ResNet50 model as inputs.\n",
        "*   It loads and preprocesses the image, then extracts features from the model's output.\n",
        "*   The resulting feature vector is normalized using L2 normalization.\n"
      ],
      "metadata": {
        "id": "FGsycz55Wp8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = []\n",
        "\n",
        "for file in os.listdir('images'):\n",
        "    filenames.append(os.path.join('images',file))\n",
        "\n",
        "feature_list = []\n",
        "\n",
        "for file in tqdm(filenames):\n",
        "    feature_list.append(extract_features(file,model))\n",
        "\n",
        "pickle.dump(feature_list,open('embeddings.pkl','wb'))\n",
        "pickle.dump(filenames,open('filenames.pkl','wb'))"
      ],
      "metadata": {
        "id": "-cbGNpPYWwUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   This creates a list of file paths for all the images in the 'images' directory.\n",
        "*   Features are extracted for each image using the extract_features function.\n",
        "\n",
        "*   The extracted features and corresponding filenames are saved using the pickle module. The features are saved in 'embeddings.pkl', and filenames are saved in 'filenames.pkl'. Both files are written in binary mode ('wb')."
      ],
      "metadata": {
        "id": "9HrUEsDlXxIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "run bellow command to generate  `embeddings.pkl` and `filenames.pkl` files"
      ],
      "metadata": {
        "id": "ygjScmo5W1TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python3 app.py"
      ],
      "metadata": {
        "id": "s78n2okOPtZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Streamlit application for an Image Recommender System**\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "1.  **Importing Libraries:**"
      ],
      "metadata": {
        "id": "pJtMdPatW9H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from numpy.linalg import norm"
      ],
      "metadata": {
        "id": "stguvqVBZ-Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "\n",
        "\n",
        "2.   **Loading Pre-trained ResNet50 Model and Feature Vectors:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = np.array(pickle.load(open('embeddings.pkl', 'rb')))\n",
        "filenames = pickle.load(open('filenames.pkl', 'rb'))\n",
        "\n",
        "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model.trainable = False\n",
        "\n",
        "model = tensorflow.keras.Sequential([\n",
        "    model,\n",
        "    GlobalMaxPooling2D()\n",
        "])"
      ],
      "metadata": {
        "id": "JodPfTG3aX-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "3.   **File Upload and Image Display:**\n",
        "\n",
        "\n",
        "*   Uses Streamlit's file_uploader to allow the user to upload an image.\n",
        "*   If an image is uploaded successfully, it is displayed on the web page using st.image.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n9Lz6zvWafkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_file = st.file_uploader(\"Choose an image\")\n",
        "if uploaded_file is not None:\n",
        "    if save_uploaded_file(uploaded_file):\n",
        "        display_image = Image.open(uploaded_file)\n",
        "        st.image(display_image)"
      ],
      "metadata": {
        "id": "COh3Fdf8apRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4.   **Feature Extraction and Recommendation:**"
      ],
      "metadata": {
        "id": "l6eNZDi_bJAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = feature_extraction(os.path.join(\"uploads\", uploaded_file.name), model)\n",
        "indices = recommend(features, feature_list)"
      ],
      "metadata": {
        "id": "HsnjMYRabQNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "5.   **Utility Functions:**\n",
        "\n"
      ],
      "metadata": {
        "id": "-vHudLxcbblt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4HZx7Gndbrh"
      },
      "outputs": [],
      "source": [
        "def save_uploaded_file(uploaded_file):\n",
        "    try:\n",
        "        with open(os.path.join('uploads',uploaded_file.name),'wb') as f:\n",
        "            f.write(uploaded_file.getbuffer())\n",
        "        return 1\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def feature_extraction(img_path,model):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "    preprocessed_img = preprocess_input(expanded_img_array)\n",
        "    result = model.predict(preprocessed_img).flatten()\n",
        "    normalized_result = result / norm(result)\n",
        "\n",
        "    return normalized_result\n",
        "\n",
        "def recommend(features,feature_list):\n",
        "    neighbors = NearestNeighbors(n_neighbors=6, algorithm='brute', metric='euclidean')\n",
        "    neighbors.fit(feature_list)\n",
        "\n",
        "    distances, indices = neighbors.kneighbors([features])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "6.   Displaying Recommended Images:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CNesipEAb848"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col1, col2, col3, col4, col5 = st.columns(5)\n",
        "\n",
        "with col1:\n",
        "    st.image(filenames[indices[0][0]])\n",
        "with col2:\n",
        "    st.image(filenames[indices[0][1]])\n",
        "with col3:\n",
        "    st.image(filenames[indices[0][2]])\n",
        "with col4:\n",
        "    st.image(filenames[indices[0][3]])\n",
        "with col5:\n",
        "    st.image(filenames[indices[0][4]])"
      ],
      "metadata": {
        "id": "mnurOl2ib8UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The recommend function is used to find the indices of the nearest neighbors based on the uploaded image's features.\n",
        "*   The top 5 recommended images are displayed in five columns using Streamlit's st.image.\n",
        "\n",
        "\n",
        "\n",
        "7.  **Run bellow command to start Streamlit application**\n",
        "\n",
        "```\n",
        "streamlit run main.py\n",
        "```"
      ],
      "metadata": {
        "id": "DVZ0lQSjcIKE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_kCnsPUqS6o"
      },
      "source": [
        "\n",
        "9.  You can now view your Streamlit app in your browser with port 8501\n",
        "\n",
        "    Link : http://localhost:8501/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
